{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gen AI APP Using Langchain (Ollama)\n",
    "\n",
    "The basic steps involve the following:\n",
    "- Setup API keys\n",
    "- Langchain for setting up project and tracing\n",
    "- Data Loader and Vector DB (For loading the data from the required source => Chunking => Embedding + Vectorisation => Vector DB)\n",
    "- ChatPrompt Template (System, Instrcutions, Context, Constraints, etc.)\n",
    "- Setting up the project chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHAMMED USAMA\\AppData\\Local\\Temp\\ipykernel_32164\\366291768.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm=Ollama(model=\"gemma:2b\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "## Ollama Llama2 model\n",
    "llm=Ollama(model=\"gemma:2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Elements of a Chat Prompt Template\n",
    "\n",
    "##### Role / System Setup\n",
    "Defines who the AI should act as.\n",
    "Example:\n",
    "\n",
    "“You are an expert data scientist helping a student understand machine learning concepts.”\n",
    "\n",
    "###### Instruction / Task\n",
    "Explains what the AI should do.\n",
    "Example:\n",
    "\n",
    "“Explain the difference between supervised and unsupervised learning.”\n",
    "\n",
    "##### Context / Background\n",
    "Provides supporting information that guides the AI’s answer.\n",
    "Example:\n",
    "\n",
    "“The student already knows basic statistics but is new to machine learning.”\n",
    "\n",
    "##### Constraints / Style\n",
    "Sets rules or format for the response.\n",
    "Example:\n",
    "\n",
    "“Answer in bullet points, keep it under 200 words.”\n",
    "\n",
    "##### Placeholders\n",
    "Slots in the template that can be filled dynamically.\n",
    "Example:\n",
    "\n",
    "“Explain {concept} as if you are teaching it to a {audience_level}.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's an answer to the question:\n",
      "\n",
      "**Langsmith** is a powerful, open-source machine learning library and ecosystem designed for data scientists and software engineers. It is known for its comprehensive functionality, ease of use, and support for a wide range of machine learning algorithms and data formats.\n",
      "\n",
      "**Key features of Langsmith include:**\n",
      "\n",
      "* **High-level APIs:** Langsmith provides intuitive APIs that allow users to quickly build and train machine learning models without needing to write low-level code.\n",
      "* **Support for multiple algorithms:** It supports a diverse set of algorithms, including linear regression, random forests, decision trees, support vector machines (SVMs), k-nearest neighbors (kNN), and more.\n",
      "* **Data handling and transformation:** Langsmith offers powerful data manipulation and transformation tools to prepare data for modeling.\n",
      "* **Data cleaning and wrangling:** It provides built-in functions for data cleaning, filtering, and wrangling, making it easy to prepare data for modeling.\n",
      "* **Evaluation and monitoring:** Langsmith includes comprehensive evaluation and monitoring tools to track model performance and identify potential issues.\n",
      "* **Community support:** The Langsmith community is active and provides support, tutorials, and resources to help users get started and solve problems.\n",
      "\n",
      "**Benefits of using Langsmith:**\n",
      "\n",
      "* **Reduced development time:** Langsmith's high-level APIs and data handling tools can significantly reduce the time required to build and train machine learning models.\n",
      "* **Improved model performance:** The extensive support for various algorithms and data formats allows users to select and fine-tune models that perform well for their specific tasks.\n",
      "* **Enhanced collaboration:** Langsmith's collaborative nature makes it easy for teams to share and work with data and models, improving efficiency.\n",
      "* **Open-source and free to use:** Langsmith is an open-source project, making it accessible and free to use.\n",
      "\n",
      "Overall, Langsmith is a powerful and versatile machine learning library that can be used by data scientists, software engineers, and data analysts of all skill levels.\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sure, I can provide you with information about Langsmith.**\n",
      "\n",
      "**Langsmith** is a **language model** trained by **Google** that focuses on generating human-quality text. It is a large language model with a massive dataset of text and code, trained on a massive dataset of text and code.\n",
      "\n",
      "**Here are some key facts about Langsmith:**\n",
      "\n",
      "* It is a **neural network** trained by Google.\n",
      "* It is a **large language model** with a massive dataset of text and code.\n",
      "* It is trained on a massive dataset of text and code.\n",
      "* It is a **multimodal language model** that can generate text, code, and other media.\n",
      "* It is used for a variety of tasks, including language translation, text generation, and question answering.\n",
      "* It is a **powerful tool for language processing** and can generate human-quality text.\n",
      "\n",
      "**Here are some examples of what Langsmith can do:**\n",
      "\n",
      "* Generate human-quality text on various topics.\n",
      "* Translate text between different languages.\n",
      "* Summarize text.\n",
      "* Write different kinds of creative content, such as poems and stories.\n",
      "\n",
      "**Here are some additional resources about Langsmith:**\n",
      "\n",
      "* **Official website:** [google.com/research/teams/langsmith]\n",
      "* **Wikipedia page:** [en.wikipedia.org/wiki/Langsmith_(language_model)]\n",
      "* **Google Cloud AI page:** [cloud.google.com/ai/research/langsmith]\n",
      "\n",
      "**I hope this information is helpful. Please let me know if you have any other questions.**\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a summary of Langsmith:\n",
      "\n",
      "**Langsmith** is a large language model (LLM) trained by Google. It is a conversational AI that can have a natural language conversation about a wide range of topics. \n",
      "\n",
      "**Key features of Langsmith:**\n",
      "\n",
      "* **Language proficiency:** It has been trained on a massive dataset of text and code, including Wikipedia, and can understand and generate human-like text in multiple languages.\n",
      "* **Conversational ability:** It can engage in conversation on a variety of topics, including personal interests, current events, and trivia.\n",
      "* **Creativity:** It can generate original and creative text formats, such as poems, code, scripts, and musical pieces.\n",
      "* **Lifelong learning:** It can continuously learn and adapt to new information and user interactions.\n",
      "\n",
      "**How to interact with Langsmith:**\n",
      "\n",
      "* **Direct messaging:** You can interact with Langsmith directly through Google Chat or other messaging apps.\n",
      "* **Web interface:** You can also interact with it through a website called Language.google.com.\n",
      "* **Command line:** You can interact with it using the command line interface.\n",
      "\n",
      "**Here are some additional things to keep in mind:**\n",
      "\n",
      "* Langsmith is not a human and does not have opinions or biases.\n",
      "* It is not a substitute for human knowledge or skill.\n",
      "* It is still under development, so it may make mistakes from time to time.\n",
      "\n",
      "I hope this information is helpful! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. Langsmith is a powerful language model developed by Google. It is a large language model with a massive dataset of text and code. Here's a summary of what I can tell you about Langsmith:\n",
      "\n",
      "**What is it?**\n",
      "\n",
      "* Langsmith is a conversational AI chatbot that can understand and generate human-like text.\n",
      "* It is trained on a massive dataset of text and code, including Wikipedia, books, and other sources.\n",
      "* It can answer questions, generate stories, translate languages, and more.\n",
      "\n",
      "**What makes it special?**\n",
      "\n",
      "* Langsmith is different from other language models like GPT-3 in that it is trained on a much larger dataset. This allows it to have a more comprehensive understanding of language and to generate more accurate responses.\n",
      "* It is also pre-trained on a massive amount of text and code, which allows it to learn and understand human language better.\n",
      "\n",
      "**What are its capabilities?**\n",
      "\n",
      "* Langsmith can:\n",
      "    * Answer questions\n",
      "    * Generate stories\n",
      "    * Translate languages\n",
      "    * Provide summaries\n",
      "    * And more\n",
      "* It can also generate different creative text formats, such as poems, code, and scripts.\n",
      "\n",
      "**How can I use it?**\n",
      "\n",
      "* You can interact with Langsmith through a conversational interface.\n",
      "* You can ask it questions about a wide range of topics.\n",
      "* You can give it a prompt, and it will generate a response.\n",
      "\n",
      "**Here are some additional facts about Langsmith:**\n",
      "\n",
      "* It was developed by Google AI in 2019.\n",
      "* It is currently the largest known language model in the world.\n",
      "* It is used by companies and individuals for a variety of purposes, including language translation, content generation, and customer service.\n",
      "\n",
      "I hope this information is helpful. Please let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Example\n",
    "\n",
    "\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# # 1. Define the Ollama model\n",
    "# llm = ChatOllama(model=\"llama3\")  # you can use mistral, phi3, etc.\n",
    "\n",
    "# # 2. Create a reusable chat prompt template\n",
    "# template = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are an expert {domain} teacher who explains concepts step by step.\"),\n",
    "#     (\"user\", \"Explain {concept} to a {audience_level}.\"),\n",
    "# ])\n",
    "\n",
    "# # 3. Fill the template with variables\n",
    "# prompt = template.format_messages(\n",
    "#     domain=\"Python programming\",\n",
    "#     concept=\"for loops\",\n",
    "#     audience_level=\"beginner\"\n",
    "# )\n",
    "\n",
    "# # 4. Run the model\n",
    "# response = llm.invoke(prompt)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Chains in LangChain\n",
    "\n",
    "1. LLMChain (most basic)\n",
    "\n",
    "    -  A single prompt template → LLM → output.\n",
    "\n",
    "2. RetrievalQA (RAG)\n",
    "\n",
    "    -  Retrieves documents from a vector database → sends them to LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The helpful answer to the question is: Building apps with local LLMs like Gemma.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Create embeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings=(\n",
    "    OllamaEmbeddings(model=\"gemma:2b\")  \n",
    ")\n",
    "\n",
    "db = FAISS.from_texts(\n",
    "    [\"LangChain helps build apps with local LLMs like Gemma.\"],\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "print(qa_chain.run(\"What does LangChain help in?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
